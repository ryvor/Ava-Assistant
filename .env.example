# Server configuration

# Port for the web server to listen on
WEB_PORT=80

# Set the debug level
# Options: log|info|warn|error
DEBUG_LEVEL=log

# Path to the models configuration file
AVA_MODELS_FILE="models.json"

# GPU configuration
#  Options: auto|off|prefer
GPU_MODE=auto

# Maximum context tokens for the model
CTX_TOKENS=4096

# Number of layers to offload to
GPU_LAYERS=20
