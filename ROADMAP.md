# Ava Development Roadmap

## Legend
	â€¢	â³ Not started
	â€¢	ğŸ”„ In progress
	â€¢	âœ… Done

â¸»

## ğŸ¯ Milestone 1 â€” Core Skeleton Online

*Ava can receive a message and reply with a hard-coded response.*

### Phase 1.1 â€” Project & Core Services
	â€¢	â³ Initialise Ava repo & base folder structure
	â€¢	â³ Set up Node + TypeScript project for the orchestrator
	â€¢	â³ Add a basic Express (or Fastify) HTTP server
	â€¢	â³ Create a POST /chat endpoint that echoes a test response

### Phase 1.2 â€” Simple CLI & Local Only
	â€¢	â³ Create a small Node CLI client that sends text to /chat
	â€¢	â³ Confirm end-to-end flow: CLI â†’ Node â†’ reply
	â€¢	â³ Add basic logging so you can see requests & responses

â¸»

## ğŸ¯ Milestone 2 â€” NLU Integration (Ava Understands You)

*Ava can recognise core intents and entities locally via Rasa.*

### Phase 2.1 â€” Rasa Setup
	â€¢	â³ Install Rasa and create a new Rasa project
	â€¢	â³ Define initial intents: greet, small_talk, order_food, book_uber, document_question
	â€¢	â³ Add ~10â€“15 example phrases per intent
	â€¢	â³ Add key entities: dish, cuisine, restaurant_name, price_preference, datetime
	â€¢	â³ Train and run the Rasa server locally

### Phase 2.2 â€” Node â†” Rasa Bridge
	â€¢	â³ Create a small NLU client in Node to call Rasaâ€™s /model/parse
	â€¢	â³ Update /chat to send user text to Rasa and log back intents/entities
	â€¢	â³ Add a confidence threshold and a simple â€œIâ€™m not sureâ€ fallback reply

â¸»

#% ğŸ¯ Milestone 3 â€” Orchestrator Brain

*Ava routes different requests to different behaviours (handlers).*

### Phase 3.1 â€” Intent Routing
	â€¢	â³ Design a simple Orchestrator class that takes (nluResult, userContext)
	â€¢	â³ Implement a handler for greet and small_talk
	â€¢	â³ Implement a stub handler for order_food (returns a fake example result)
	â€¢	â³ Implement a stub handler for book_uber (returns a fake example result)
	â€¢	â³ Implement a stub handler for document_question

### Phase 3.2 â€” Low-Confidence Active Learning
	â€¢	â³ Add logic: if intent confidence is low â†’ ask user â€œDid you mean X?â€
	â€¢	â³ Store low-confidence messages in a DB table for later review/labelling
	â€¢	â³ Implement a simple â€œyes/no/never mindâ€ clarification flow

â¸»

## ğŸ¯ Milestone 4 â€” Personalisation & Style

*Ava starts talking more like you and remembers basic context.*

### Phase 4.1 â€” User & Memory Basics
	â€¢	â³ Add a users table and a simple user lookup by ID/phone
	â€¢	â³ Add a basic conversation_memory or user_context table
	â€¢	â³ Store last interaction time and a simple message count per user

### Phase 4.2 â€” Style Profile
	â€¢	â³ Create a style_profile table (formality, emoji use, sentence length, etc.)
	â€¢	â³ Add a basic style analyser that inspects each user message (formal vs casual, emoji, etc.)
	â€¢	â³ Update the style profile over time using a moving average

### Phase 4.3 â€” Response Generation Layer
	â€¢	â³ Create a respond(label, context) function in the orchestrator
	â€¢	â³ Implement personalised greetings using time of day + style profile
	â€¢	â³ Implement natural confirmations (e.g. â€œAll sortedâ€, â€œDoneâ€, â€œGotchaâ€)
	â€¢	â³ Implement friendly clarification responses for low-confidence cases

â¸»

## ğŸ¯ Milestone 5 â€” Local Document Understanding

*Ava can read a document you upload and answer simple questions about it.*

### Phase 5.1 â€” Document Storage & Text Extraction
	â€¢	â³ Create a documents table for file metadata and extracted text
	â€¢	â³ Add a local file upload endpoint (web or CLI pointing to a file)
	â€¢	â³ Integrate a local text extractor (PDF and plain text first)
	â€¢	â³ Save extracted text into the DB and mark it as the userâ€™s â€œactive documentâ€

### Phase 5.2 â€” Basic Document Q&A
	â€¢	â³ Extend document_question intent training (e.g. â€œwhat does this say?â€, â€œdo they have burgers?â€, â€œwhat is this in GBP?â€)
	â€¢	â³ In the document_question handler, load the active documentâ€™s text
	â€¢	â³ Implement simple â€œcontains itemâ€ checks (e.g. search for â€œburgerâ€ lines)
	â€¢	â³ Implement a basic â€œsummarise thisâ€ behaviour (truncate or simple keyword summary)
	â€¢	â³ Implement simple currency detection + conversion logic (with an optional offline or whitelisted FX source)

â¸»

## ğŸ¯ Milestone 6 â€” Privacy & Safety Hardening

*Ava becomes a tightly locked-down, local-first assistant.*

### Phase 6.1 â€” Data Handling & Retention
	â€¢	â³ Add a 30-day retention policy for uploaded files + documents
	â€¢	â³ Implement a daily cleanup job that deletes old files and DB rows
	â€¢	â³ Ensure logs do not contain sensitive document content or secrets

### Phase 6.2 â€” Network & Egress Control
	â€¢	â³ Centralise all external HTTP calls into a safeFetch helper
	â€¢	â³ Restrict allowed hostnames to a strict whitelist
	â€¢	â³ Add firewall rules / router rules to block outbound traffic except to whitelisted services (or none at all for now)

### Phase 6.3 â€” Config & Modes
	â€¢	â³ Add a config flag for â€œoffline-onlyâ€ mode vs â€œallow-online-lookupsâ€
	â€¢	â³ Make online lookup intents explicitly opt-in (â€œlook this up onlineâ€)
	â€¢	â³ Add clear logging whenever Ava goes online for transparency

â¸»

## ğŸ¯ Milestone 7 â€” Conversational Ava

*Ava can chat naturally, not just execute commands.*

### Phase 7.1 â€” Small Talk & Dialog Moves
	â€¢	â³ Improve small_talk training data (examples of â€œhow are youâ€, â€œIâ€™m boredâ€, â€œtalk to meâ€, etc.)
	â€¢	â³ Add a small_talk handler that chooses between greeting, empathising, asking a question, or reacting
	â€¢	â³ Make small-talk responses adapt to the userâ€™s style profile (formal vs casual, emoji use, etc.)

### Phase 7.2 â€” Light Conversation Memory
	â€¢	â³ Store recent topics/keywords in conversation_memory
	â€¢	â³ Add callbacks like â€œhow did that trip go?â€ based on previous mentions
	â€¢	â³ Make Ava optionally ask simple follow-up questions to keep chat flowing
